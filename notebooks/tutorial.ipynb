{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's define few tables in Pydantic style."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pgvector.sqlalchemy import Vector\n",
    "from sqlmodel import Field, SQLModel, Column, Relationship\n",
    "\n",
    "from microsearch import TrigramIndex, FullTextIndex\n",
    "\n",
    "\n",
    "# The Meta table contains metadata of the document.\n",
    "class Meta(SQLModel, table=True):\n",
    "    id: int | None = Field(default=None, primary_key=True)\n",
    "    title: str\n",
    "\n",
    "    # This is how you define relationship to document(s) referencing this Meta object\n",
    "    documents: list[\"Document\"] | None = Relationship(back_populates=\"meta\")\n",
    "\n",
    "\n",
    "\n",
    "class Document(SQLModel, table=True):\n",
    "    id: int | None = Field(default=None, primary_key=True)\n",
    "    text: str\n",
    "\n",
    "    # This column will store embedding vectors for semantic search\n",
    "    vector: list[float] = Field(default=None, sa_column=Column(Vector(dim=384)))\n",
    "\n",
    "    # Foreign key to Meta object and property-like accessor to Meta object.\n",
    "    meta_id: int | None = Field(default=None, foreign_key=\"meta.id\")\n",
    "    meta: Meta | None = Relationship(back_populates=\"documents\")\n",
    "\n",
    "    # This will create index over text column for trigram search\n",
    "    __table_args__ = (\n",
    "        TrigramIndex(table=\"document\", column=\"text\"),\n",
    "        FullTextIndex(table=\"document\", column=\"text\"),\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And create tables and indices in the database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlmodel import create_engine\n",
    "\n",
    "engine = create_engine(\"postgresql://admin:admin@localhost:5432/db\", echo=False)\n",
    "\n",
    "SQLModel.metadata.create_all(engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sqlmodel import Session, text\n",
    "\n",
    "# with Session(engine) as session:\n",
    "#     session.exec(text(\"DROP TABLE document\"))\n",
    "#     session.exec(text(\"DROP TABLE meta\"))\n",
    "#     session.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define embedding function for vector search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ollama\n",
    "\n",
    "def embed(text: str) -> list[float]:\n",
    "    return ollama.embed(model=\"all-minilm:33m\", input=text).embeddings[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download and index example data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import batched\n",
    "\n",
    "import httpx\n",
    "from sqlmodel import Session\n",
    "\n",
    "\n",
    "book = httpx.get(\"https://www.gutenberg.org/cache/epub/2591/pg2591.txt\").text\n",
    "\n",
    "docs = []\n",
    "for no, words in enumerate(batched(book.split(), n=100)):\n",
    "    chunk = \" \".join(words)\n",
    "    meta = Meta(title=f\"Document number {no}\")\n",
    "    doc = Document(text=chunk, vector=embed(chunk), meta=meta)\n",
    "    docs.append(doc)\n",
    "\n",
    "\n",
    "with Session(engine) as session:\n",
    "    session.add_all(docs)\n",
    "    session.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform hybrid search with RRF reranker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%timeit -n 5\n",
    "\n",
    "from microsearch import Result, microsearch, weighted_reciprocal_rank, wrapped\n",
    "\n",
    "query = \"the queen bee\"\n",
    "query_vec = embed(\"the queen bee\")\n",
    "\n",
    "\n",
    "def ident(doc: Result[Document]) -> str:\n",
    "    \"\"\"Return unique (hashable) property of the object.\"\"\"\n",
    "    return doc.item.id\n",
    "\n",
    "\n",
    "with microsearch(engine) as use:\n",
    "    docs, scores = weighted_reciprocal_rank(\n",
    "        arrays=[\n",
    "            use.fulltext(table=Document, query=query),\n",
    "            use.semantic(table=Document, query=embed(query)),\n",
    "            use.trigram(table=Document, query=query, strict=True),\n",
    "        ],\n",
    "        ident_fn=ident,\n",
    "    )\n",
    "\n",
    "    # len(docs)\n",
    "    for i, doc in enumerate(docs[:20], start=1):\n",
    "        print(\n",
    "            f\"{i:>5} | {doc.kind:^8} | {doc.score:>5.4f} | \",\n",
    "            wrapped(doc.item.text[:60] + \"...\"),\n",
    "            sep=\"\",\n",
    "        )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
